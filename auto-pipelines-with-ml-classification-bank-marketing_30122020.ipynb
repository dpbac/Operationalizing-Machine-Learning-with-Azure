{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update version 28/12/2020 following videos of Lesson 4 Section 5 and checking notebook provided**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning Pipeline with AutoMLStep \n",
    "\n",
    "This notebook is part of [Project 2: Operationalizing Machine Learning with Azure](https://github.com/dpbac/Operationalizing-Machine-Learning-with-Azure) of the `Udacity Nanodegree Program : Machine Learning Engineer with Azure`.\n",
    "\n",
    "In this project you will continue working with the Bank Dataset introduced in [Project 1: Optimizing an ML Pipeline in Azure](https://github.com/dpbac/Optimizing-an-ML-Pipeline-in-Azure). We will use Azure in this project to configure a cloud-based machine learning product model, deploy it, and consume it.\n",
    "\n",
    "**REVIEW AND COMPLETE ALL TEXT BELOW**\n",
    "\n",
    "This notebook demonstrates the use of AutoMLStep in Azure Machine Learning Pipeline.\n",
    "\n",
    "A model is generated using AutoML for classifcation using the dataset available at https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this example we showcase how you can use AzureML Dataset to load data for AutoML via AML Pipeline. \n",
    "\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you have executed the [configuration](https://aka.ms/pl-config) before running this notebook.\n",
    "\n",
    "In this notebook the following steps are performed\n",
    "\n",
    "1. Create an `Experiment` in an existing `Workspace`.\n",
    "2. Create or Attach existing AmlCompute to a workspace.\n",
    "3. Define data loading in a `TabularDataset`.\n",
    "4. Configure AutoML using `AutoMLConfig`.\n",
    "5. Use AutoMLStep\n",
    "6. Train the model using AmlCompute\n",
    "7. Explore the results.\n",
    "8. Test the best fitted model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Machine Learning and Pipeline SDK-specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.19.0\n"
     ]
    }
   ],
   "source": [
    "# Azure Machine Learning and Pipeline SDK-specific imports\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import pkg_resources\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "Initialize a workspace object from persisted configuration. Make sure the config file is present at .\\config.json\n",
    "\n",
    "The config.json can be downloaded in the overview of Azure portal. (**Do I need to download?**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick-starts-ws-132158\n",
      "aml-quickstarts-132158\n",
      "southcentralus\n",
      "f9d5a085-54dc-4215-9ba6-dad5d86e60a0\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML experiment\n",
    "\n",
    "**REVIEW AND UPDATE TEXT**\n",
    "**ATTENTION NAME OF THE EXPERIMENT**\n",
    "\n",
    "Let's create an experiment named \"automlstep-classification\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure.\n",
    "\n",
    "The best practice is to use separate folders for scripts and its dependent files for each step and specify that folder as the `source_directory` for the step. This helps reduce the size of the snapshot created for the step (only the specific folder is snapshotted). Since changes in any files in the `source_directory` would trigger a re-upload of the snapshot, this helps keep the reuse of the step when there are no changes in the `source_directory` of the step.\n",
    "\n",
    "*Udacity Note:* There is no need to create an Azure ML experiment, this needs to re-use the experiment that was already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>automl-experiment</td><td>quick-starts-ws-132158</td><td><a href=\"https://ml.azure.com/experiments/automl-experiment?wsid=/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourcegroups/aml-quickstarts-132158/workspaces/quick-starts-ws-132158\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: automl-experiment,\n",
       "Workspace: quick-starts-ws-132158)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a name for the run history container in the workspace.\n",
    "# NOTE: update these to match your existing exp name\n",
    "experiment_name = 'automl-experiment'\n",
    "project_folder = './pipeline-project'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Workspace name</th>\n",
       "      <td>quick-starts-ws-132158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azure region</th>\n",
       "      <td>southcentralus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription id</th>\n",
       "      <td>f9d5a085-54dc-4215-9ba6-dad5d86e60a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource group</th>\n",
       "      <td>aml-quickstarts-132158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>automl-experiment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     \n",
       "Workspace name                 quick-starts-ws-132158\n",
       "Azure region                           southcentralus\n",
       "Subscription id  f9d5a085-54dc-4215-9ba6-dad5d86e60a0\n",
       "Resource group                 aml-quickstarts-132158\n",
       "Experiment Name                     automl-experiment"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_data = {'Workspace name': ws.name,\n",
    "            'Azure region': ws.location,\n",
    "            'Subscription id': ws.subscription_id,\n",
    "            'Resource group': ws.resource_group,\n",
    "            'Experiment Name': experiment.name}\n",
    "\n",
    "df_data = pd.DataFrame.from_dict(data = dic_data, orient='index')\n",
    "\n",
    "df_data.rename(columns={0:''}, inplace = True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach an AmlCompute cluster\n",
    "\n",
    "Now that we have initialized our workspace and created our experiment, it is time to define our resources. This means we need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for your AutoML run.\n",
    "\n",
    "In this section you will create default compute clusters for use by the notebook and any other necessary operations we need. Here we get the default `AmlCompute` as your training compute resource.\n",
    "\n",
    "In order to create a cluster we need to specify a compute configuration that defines the `type of machine` to be used and the `scalability behaviors`. Also, it is necessary to define the name of the cluster which must be unique within the workspace. This name is used to address the cluster later.\n",
    "\n",
    "For this project we use a CPU cluster with following parameters:\n",
    "\n",
    "* `type of the machine`:\n",
    "\n",
    "    * `vm_size`: Defines the size of the virtual machine. We use here \"STANDARD_DS12_V2\" (more details [here](https://docs.microsoft.com/en-us/azure/cloud-services/cloud-services-sizes-specs#dv2-series))\n",
    "\n",
    "* `Scalability behaviors`:\n",
    "\n",
    "    * `min_nodes`: Sets minimun size of the cluster. Setting the minimum to 0 the cluster will shut down all nodes while not in use. If you use another value you are able to have faster start-up times, but you will also be billed when the cluster is not in use. In this experiment we define `min_nodes` as 1.\n",
    "\n",
    "    * `max_nodes`: Sets the maximun size of the cluster. Larger number allows for more concurrency and a greater distributed processing of scale-out jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cpu-cluster. Use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Define CPU cluster name\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing cpu-cluster. Use it.\")\n",
    "except ComputeTargetException:\n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_DS12_V2\",\n",
    "                                                           #vm_priority = 'lowpriority', # optional\n",
    "                                                           min_nodes=1, # when innactive\n",
    "                                                           max_nodes=4) # when busy\n",
    "\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "# can poll for a minimum number of nodes and for a specific timeout. \n",
    "# if no min node count is provided it will use the scale settings for the cluster\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\n",
    "\n",
    "# For a more detailed view of current AmlCompute status, use get_status()\n",
    "print(cpu_cluster.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu-cluster ComputeInstance Succeeded\n"
     ]
    }
   ],
   "source": [
    "# Check details about compute_targets (i.e. cpu_cluster)\n",
    "\n",
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The code below try first to load the dataset from the workspace. The key is the dataset name and is used to find the dataset and load it.\n",
    "\n",
    "If the key is not found, i.e., the dataset is not in the workspace the dataset is loaded from the web using the link given at the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load the dataset from the Workspace. Otherwise, create it from the file\n",
    "# NOTE: update the key to match the dataset name\n",
    "found = False\n",
    "key = \"BankMarketing\"\n",
    "description_text = \"Bank Marketing DataSet for 2nd Project Udacity Azure ML Engineer.\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True\n",
    "        dataset = ws.datasets[key] \n",
    "\n",
    "if not found:\n",
    "        # Create AML Dataset and register it into Workspace\n",
    "        example_data = 'https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv'\n",
    "        # Create TabularDataset using TabularDatasetFactory\n",
    "        dataset = Dataset.Tabular.from_delimited_files(example_data)        \n",
    "        #Register Dataset in Workspace\n",
    "        dataset = dataset.register(workspace=ws,\n",
    "                                   name=key,\n",
    "                                   description=description_text)\n",
    "\n",
    "\n",
    "#create a data frame\n",
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.299</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>unknown</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.860</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.967</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital    education  default housing loan    contact  \\\n",
       "0   57   technician  married  high.school       no      no  yes   cellular   \n",
       "1   55      unknown  married      unknown  unknown     yes   no  telephone   \n",
       "2   33  blue-collar  married     basic.9y       no      no   no   cellular   \n",
       "3   36       admin.  married  high.school       no      no   no  telephone   \n",
       "4   27    housemaid  married  high.school       no     yes   no   cellular   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         1      failure         -1.8   \n",
       "1   may         thu  ...         2    999         0  nonexistent          1.1   \n",
       "2   may         fri  ...         1    999         1      failure         -1.8   \n",
       "3   jun         fri  ...         4    999         0  nonexistent          1.4   \n",
       "4   jul         fri  ...         2    999         0  nonexistent          1.4   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          92.893          -46.2      1.299       5099.1  no  \n",
       "1          93.994          -36.4      4.860       5191.0  no  \n",
       "2          92.893          -46.2      1.313       5099.1  no  \n",
       "3          94.465          -41.8      4.967       5228.1  no  \n",
       "4          93.918          -42.7      4.963       5228.1  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32950 entries, 0 to 32949\n",
      "Data columns (total 21 columns):\n",
      "age               32950 non-null int64\n",
      "job               32950 non-null object\n",
      "marital           32950 non-null object\n",
      "education         32950 non-null object\n",
      "default           32950 non-null object\n",
      "housing           32950 non-null object\n",
      "loan              32950 non-null object\n",
      "contact           32950 non-null object\n",
      "month             32950 non-null object\n",
      "day_of_week       32950 non-null object\n",
      "duration          32950 non-null int64\n",
      "campaign          32950 non-null int64\n",
      "pdays             32950 non-null int64\n",
      "previous          32950 non-null int64\n",
      "poutcome          32950 non-null object\n",
      "emp.var.rate      32950 non-null float64\n",
      "cons.price.idx    32950 non-null float64\n",
      "cons.conf.idx     32950 non-null float64\n",
      "euribor3m         32950 non-null float64\n",
      "nr.employed       32950 non-null float64\n",
      "y                 32950 non-null object\n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.040212</td>\n",
       "      <td>257.335205</td>\n",
       "      <td>2.561730</td>\n",
       "      <td>962.174780</td>\n",
       "      <td>0.174780</td>\n",
       "      <td>0.076228</td>\n",
       "      <td>93.574243</td>\n",
       "      <td>-40.518680</td>\n",
       "      <td>3.615654</td>\n",
       "      <td>5166.859608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.432313</td>\n",
       "      <td>257.331700</td>\n",
       "      <td>2.763646</td>\n",
       "      <td>187.646785</td>\n",
       "      <td>0.496503</td>\n",
       "      <td>1.572242</td>\n",
       "      <td>0.578636</td>\n",
       "      <td>4.623004</td>\n",
       "      <td>1.735748</td>\n",
       "      <td>72.208448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>92.201000</td>\n",
       "      <td>-50.800000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>4963.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>93.075000</td>\n",
       "      <td>-42.700000</td>\n",
       "      <td>1.344000</td>\n",
       "      <td>5099.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>93.749000</td>\n",
       "      <td>-41.800000</td>\n",
       "      <td>4.857000</td>\n",
       "      <td>5191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>93.994000</td>\n",
       "      <td>-36.400000</td>\n",
       "      <td>4.961000</td>\n",
       "      <td>5228.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>94.767000</td>\n",
       "      <td>-26.900000</td>\n",
       "      <td>5.045000</td>\n",
       "      <td>5228.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age      duration      campaign         pdays      previous  \\\n",
       "count  32950.000000  32950.000000  32950.000000  32950.000000  32950.000000   \n",
       "mean      40.040212    257.335205      2.561730    962.174780      0.174780   \n",
       "std       10.432313    257.331700      2.763646    187.646785      0.496503   \n",
       "min       17.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "25%       32.000000    102.000000      1.000000    999.000000      0.000000   \n",
       "50%       38.000000    179.000000      2.000000    999.000000      0.000000   \n",
       "75%       47.000000    318.000000      3.000000    999.000000      0.000000   \n",
       "max       98.000000   4918.000000     56.000000    999.000000      7.000000   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m   nr.employed  \n",
       "count  32950.000000    32950.000000   32950.000000  32950.000000  32950.000000  \n",
       "mean       0.076228       93.574243     -40.518680      3.615654   5166.859608  \n",
       "std        1.572242        0.578636       4.623004      1.735748     72.208448  \n",
       "min       -3.400000       92.201000     -50.800000      0.634000   4963.600000  \n",
       "25%       -1.800000       93.075000     -42.700000      1.344000   5099.100000  \n",
       "50%        1.100000       93.749000     -41.800000      4.857000   5191.000000  \n",
       "75%        1.400000       93.994000     -36.400000      4.961000   5228.100000  \n",
       "max        1.400000       94.767000     -26.900000      5.045000   5228.100000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     0.887951\n",
       "yes    0.112049\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced data: 88.80% label 'no' and 11.20% label 'yes'.\n",
    "\n",
    "We can apply some techniques on the dataset to make the data more balanced before applying ML. **Automated ML** has built in capabilities to help deal with imbalanced. For instances, the algorithms used by automated ML detect imbalance when the number of samples in the minority class is equal to or fewer than 20% of the number of samples in the majority class, where minority class refers to the one with fewest samples and majority class refers to the one with most samples. Subsequently, AutoML will run an experiment with sub-sampled data to check if using class weights would remedy this problem and improve performance.\n",
    "\n",
    "In addition, it is important to use a more appropriated metric such as **AUC_weighted** which is a primary metric that calculates the contribution of every class based on the relative number of samples representing that class. Therefore, it is more robust against imbalance.\n",
    "\n",
    "For more details, check this [link](https://docs.microsoft.com/en-us/azure/machine-learning/concept-manage-ml-pitfalls).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model:\n",
    "\n",
    "Now we use the [BankMarketing Dataset](https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv) to obtain a model by running AutoML.\n",
    "\n",
    "AutoML is an automated machine learning capability included in Azure ML. It leverages the scalability of cloud compute to automatically try multiple pre-processing techniques and model-training algorithms in parallel to find the best performing supervised machine learning model for a dataset. In this particular case for the `BankMarketing` dataset, we have just loaded.\n",
    "\n",
    "### Configure AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 60, # define how long, in minutes, the experiment should continue to run.\n",
    "    \"max_concurrent_iterations\": 5,\n",
    "    \"primary_metric\" : 'AUC_weighted'\n",
    "}\n",
    "automl_config = AutoMLConfig(compute_target=cpu_cluster,\n",
    "                             task = \"classification\",\n",
    "                             training_data=dataset,\n",
    "                             label_column_name=\"y\",   \n",
    "                             path = project_folder,\n",
    "                             enable_early_stopping= True,\n",
    "                             featurization= 'auto', # as part of preprocessing, data guardrails and featurization steps are performed automatically.\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline and AutoMLStep\n",
    "\n",
    "You can define outputs for the AutoMLStep using TrainingOutput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "metrics_output_name = 'metrics_output'\n",
    "best_model_output_name = 'best_model_output'\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=metrics_output_name,\n",
    "                           training_output=TrainingOutput(type='Metrics'))\n",
    "model_data = PipelineData(name='model_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=best_model_output_name,\n",
    "                           training_output=TrainingOutput(type='Model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an AutoMLStep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_step = AutoMLStep(\n",
    "    name='automl_module',\n",
    "    automl_config=automl_config,\n",
    "    outputs=[metrics_data, model_data],\n",
    "    allow_reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the pipeline using the `automl_step` just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "pipeline = Pipeline(\n",
    "    description=\"pipeline_with_automlstep\",\n",
    "    workspace=ws,    \n",
    "    steps=[automl_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Results\n",
    "\n",
    "### Retrieve the metrics of all child runs\n",
    "Outputs of above run can be used as inputs of other steps in pipeline. \n",
    "\n",
    "In this section wetest the pipeline and retrieve the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\n",
    "num_file_downloaded = metrics_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(metrics_output._path_on_datastore) as f:\n",
    "    metrics_output_result = f.read()\n",
    "    \n",
    "deserialized_metrics_output = json.loads(metrics_output_result)\n",
    "df = pd.DataFrame(deserialized_metrics_output)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve best model from Pipeline Run\n",
    "best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\n",
    "num_file_downloaded = best_model_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(best_model_output._path_on_datastore, \"rb\" ) as f:\n",
    "    best_model = pickle.load(f)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "#### Load Test Data\n",
    "For the test data, it should have the same preparation step as the train data. Otherwise it might get failed at the preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = Dataset.Tabular.from_delimited_files(path='https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv')\n",
    "df_test = dataset_test.to_pandas_dataframe()\n",
    "df_test = df_test[pd.notnull(df_test['y'])]\n",
    "\n",
    "y_test = df_test['y']\n",
    "X_test = df_test.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Testing Our Best Fitted Model\n",
    "\n",
    "We will use confusion matrix to see how our model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ypred = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confusion matrix\n",
    "pd.DataFrame(cm).style.background_gradient(cmap='Blues', low=0, high=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish and run from REST endpoint\n",
    "\n",
    "Publishing a pipeline is the process of making a pipeline publicly available. Here we will use Python SDK to publish our pipeline.\n",
    "\n",
    "The following code publish the pipeline to your workspace. In your workspace in the portal, you can see metadata for the pipeline including run history and durations. You can also run the pipeline manually from the portal.\n",
    "\n",
    "Additionally, publishing a pipeline, a public HTTP endpoint becomes available, allowing other services, including external ones, to interact with an Azure Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"Bankmarketing Train\", \n",
    "    description=\"Training bankmarketing pipeline\", \n",
    "    version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate once again, to retrieve the `auth_header` so that the endpoint can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the REST url from the endpoint property of the published pipeline object. You can also find the REST url in your workspace in the portal. Build an HTTP POST request to the endpoint, specifying your authentication header. Additionally, add a JSON payload object with the experiment name and the batch size parameter. As a reminder, the process_count_per_node is passed through to ParallelRunStep because you defined it is defined as a PipelineParameter object in the step configuration.\n",
    "\n",
    "Make the request to trigger the run. Access the Id key from the response dict to get the value of the run id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": \"pipeline-rest-endpoint\"}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response.raise_for_status()\n",
    "except Exception:    \n",
    "    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n",
    "                    \"Response Code: {}\\n\"\n",
    "                    \"Headers: {}\\n\"\n",
    "                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n",
    "\n",
    "run_id = response.json().get('Id')\n",
    "print('Submitted pipeline run: ', run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the run id to monitor the status of the new run. This will take another 10-15 min to run and will look similar to the previous pipeline run, so if you don't need to see another pipeline run, you can skip watching the full output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[\"pipeline-rest-endpoint\"], run_id)\n",
    "RunDetails(published_pipeline_run).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
